{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "UD9yxfoTJ2i5",
    "outputId": "b1f32ad4-a0b9-4cab-e85d-cd246a9c2815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 86.3MB 130kB/s \n",
      "\u001b[K     |████████████████████████████████| 3.8MB 51.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 450kB 47.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
      "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install -U tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "dcb189fc-5ad3-4422-9015-df25cb80835f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "5a37b5d0-e39b-46b8-ed42-f6c86ad3dc29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uU0i937SShJ5",
    "outputId": "d91fdcd9-c5d3-4e8d-ff16-17844d8efba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_labels = testY[0:10]\n",
    "display_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "0af698b9-de51-4ba1-ba15-86d154d21274",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RVw2HNq3PZLW",
    "outputId": "6ba271d7-1235-4e6c-d4da-6a253c9b53fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "nYvy2MbLcb6X",
    "outputId": "e6deba87-f88a-41e0-d458-de67d2455d21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff653ed0c88>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets print the image as well\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(trainX[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "FDbjpb7Pc5LA",
    "outputId": "701d4789-2dd5-4eca-e85a-ae07a5ac0a56"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAABVCAYAAABn9w3LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 864x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(display_labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "O59C_-IgOIVB",
    "outputId": "40a7cb58-5d96-43e5-f3f6-9820d5a1c59b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 6281.8595 - accuracy: 0.7394 - val_loss: 6291.9395 - val_accuracy: 0.7149\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 4826.7328 - accuracy: 0.7792 - val_loss: 7750.8406 - val_accuracy: 0.6565\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4502.9668 - accuracy: 0.7861 - val_loss: 7535.1862 - val_accuracy: 0.7012\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4659.6241 - accuracy: 0.7868 - val_loss: 4881.4646 - val_accuracy: 0.7653\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 4368.4506 - accuracy: 0.7951 - val_loss: 4604.5068 - val_accuracy: 0.7727\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4469.6525 - accuracy: 0.7927 - val_loss: 3015.7093 - val_accuracy: 0.8189\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4443.3186 - accuracy: 0.7937 - val_loss: 2961.4755 - val_accuracy: 0.8183\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4239.1180 - accuracy: 0.8012 - val_loss: 5260.1440 - val_accuracy: 0.7844\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4474.2347 - accuracy: 0.7955 - val_loss: 7519.9690 - val_accuracy: 0.7376\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 4308.5423 - accuracy: 0.7997 - val_loss: 6938.3109 - val_accuracy: 0.7541\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4310.7360 - accuracy: 0.8007 - val_loss: 3017.9152 - val_accuracy: 0.8180\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4367.6298 - accuracy: 0.7998 - val_loss: 3800.0803 - val_accuracy: 0.8152\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4349.4289 - accuracy: 0.8012 - val_loss: 2983.4374 - val_accuracy: 0.8273\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4258.0427 - accuracy: 0.8023 - val_loss: 10122.6048 - val_accuracy: 0.7388\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4183.7772 - accuracy: 0.8021 - val_loss: 7862.8077 - val_accuracy: 0.7177\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4254.4086 - accuracy: 0.8027 - val_loss: 3653.7661 - val_accuracy: 0.8102\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 4201.0968 - accuracy: 0.8067 - val_loss: 5008.9467 - val_accuracy: 0.7983\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4177.2744 - accuracy: 0.8051 - val_loss: 3277.7033 - val_accuracy: 0.8132\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4196.0693 - accuracy: 0.8050 - val_loss: 5659.5367 - val_accuracy: 0.7983\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4239.3281 - accuracy: 0.8055 - val_loss: 3510.8009 - val_accuracy: 0.8036\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 4090.6809 - accuracy: 0.8073 - val_loss: 4414.2758 - val_accuracy: 0.7868\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4123.8968 - accuracy: 0.8062 - val_loss: 8902.9312 - val_accuracy: 0.6645\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4066.2702 - accuracy: 0.8062 - val_loss: 3947.5672 - val_accuracy: 0.8222\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4051.2268 - accuracy: 0.8094 - val_loss: 4579.8352 - val_accuracy: 0.7578\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4085.2183 - accuracy: 0.8069 - val_loss: 3572.3620 - val_accuracy: 0.7952\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4082.7313 - accuracy: 0.8081 - val_loss: 5789.7572 - val_accuracy: 0.7726\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4143.3307 - accuracy: 0.8060 - val_loss: 3622.5082 - val_accuracy: 0.8094\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4103.5289 - accuracy: 0.8078 - val_loss: 4290.9794 - val_accuracy: 0.7816\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 4230.5298 - accuracy: 0.8057 - val_loss: 3431.7800 - val_accuracy: 0.8008\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 4124.2916 - accuracy: 0.8088 - val_loss: 6184.5251 - val_accuracy: 0.7700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff65b600da0>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "U3x-R4F6YHsR",
    "outputId": "68d0adcb-66d8-4669-b68b-58639cd3f2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "A8qVuAPwYoX4",
    "outputId": "2f67e247-9935-4981-af6c-ec510bf894b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 10,986\n",
      "Trainable params: 9,418\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JNLR8tcBOIVP",
    "outputId": "70d1bf53-d5f1-4ded-e550-211c5d43f1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.5590 - accuracy: 0.8076 - val_loss: 0.5039 - val_accuracy: 0.8316\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4829 - accuracy: 0.8329 - val_loss: 0.4961 - val_accuracy: 0.8284\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4688 - accuracy: 0.8385 - val_loss: 0.4853 - val_accuracy: 0.8387\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4618 - accuracy: 0.8396 - val_loss: 0.5041 - val_accuracy: 0.8304\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4540 - accuracy: 0.8431 - val_loss: 0.4797 - val_accuracy: 0.8404\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4529 - accuracy: 0.8433 - val_loss: 0.5038 - val_accuracy: 0.8307\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4476 - accuracy: 0.8449 - val_loss: 0.5129 - val_accuracy: 0.8314\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4488 - accuracy: 0.8435 - val_loss: 0.4906 - val_accuracy: 0.8312\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4405 - accuracy: 0.8462 - val_loss: 0.4783 - val_accuracy: 0.8393\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4379 - accuracy: 0.8470 - val_loss: 0.5078 - val_accuracy: 0.8357\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4372 - accuracy: 0.8464 - val_loss: 0.4985 - val_accuracy: 0.8363\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4374 - accuracy: 0.8485 - val_loss: 0.4934 - val_accuracy: 0.8361\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4385 - accuracy: 0.8463 - val_loss: 0.5281 - val_accuracy: 0.8343\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4338 - accuracy: 0.8478 - val_loss: 0.5024 - val_accuracy: 0.8331\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4336 - accuracy: 0.8484 - val_loss: 0.5170 - val_accuracy: 0.8327\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4332 - accuracy: 0.8477 - val_loss: 0.4966 - val_accuracy: 0.8362\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4287 - accuracy: 0.8511 - val_loss: 0.5289 - val_accuracy: 0.8376\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4319 - accuracy: 0.8482 - val_loss: 0.4946 - val_accuracy: 0.8362\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4305 - accuracy: 0.8474 - val_loss: 0.5064 - val_accuracy: 0.8306\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4290 - accuracy: 0.8506 - val_loss: 0.5115 - val_accuracy: 0.8290\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4297 - accuracy: 0.8497 - val_loss: 0.5048 - val_accuracy: 0.8385\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4262 - accuracy: 0.8504 - val_loss: 0.5094 - val_accuracy: 0.8333\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4280 - accuracy: 0.8493 - val_loss: 0.5069 - val_accuracy: 0.8357\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4238 - accuracy: 0.8507 - val_loss: 0.5106 - val_accuracy: 0.8370\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4261 - accuracy: 0.8499 - val_loss: 0.4947 - val_accuracy: 0.8351\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4254 - accuracy: 0.8508 - val_loss: 0.5147 - val_accuracy: 0.8367\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4233 - accuracy: 0.8512 - val_loss: 0.5112 - val_accuracy: 0.8351\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4245 - accuracy: 0.8488 - val_loss: 0.4990 - val_accuracy: 0.8317\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4251 - accuracy: 0.8504 - val_loss: 0.5178 - val_accuracy: 0.8359\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4241 - accuracy: 0.8500 - val_loss: 0.4920 - val_accuracy: 0.8372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff65a1242e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pJUqA5T4OIVc",
    "outputId": "462385db-9333-4bcb-993a-25def5d9fb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.9480 - accuracy: 0.6738 - val_loss: 0.6981 - val_accuracy: 0.7653\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.6486 - accuracy: 0.7760 - val_loss: 0.6124 - val_accuracy: 0.7918\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.5926 - accuracy: 0.7950 - val_loss: 0.5873 - val_accuracy: 0.8035\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.5611 - accuracy: 0.8064 - val_loss: 0.5773 - val_accuracy: 0.8092\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.5431 - accuracy: 0.8107 - val_loss: 0.5421 - val_accuracy: 0.8165\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.5303 - accuracy: 0.8170 - val_loss: 0.5369 - val_accuracy: 0.8193\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.5184 - accuracy: 0.8216 - val_loss: 0.5499 - val_accuracy: 0.8203\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.5106 - accuracy: 0.8227 - val_loss: 0.5175 - val_accuracy: 0.8235\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.5046 - accuracy: 0.8256 - val_loss: 0.5225 - val_accuracy: 0.8250\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4984 - accuracy: 0.8285 - val_loss: 0.5032 - val_accuracy: 0.8263\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4934 - accuracy: 0.8296 - val_loss: 0.5170 - val_accuracy: 0.8272\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4866 - accuracy: 0.8320 - val_loss: 0.5121 - val_accuracy: 0.8275\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4849 - accuracy: 0.8335 - val_loss: 0.5001 - val_accuracy: 0.8282\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4816 - accuracy: 0.8342 - val_loss: 0.4997 - val_accuracy: 0.8300\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4781 - accuracy: 0.8362 - val_loss: 0.4878 - val_accuracy: 0.8305\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4739 - accuracy: 0.8366 - val_loss: 0.5030 - val_accuracy: 0.8328\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4723 - accuracy: 0.8374 - val_loss: 0.4915 - val_accuracy: 0.8331\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4683 - accuracy: 0.8387 - val_loss: 0.5020 - val_accuracy: 0.8329\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4669 - accuracy: 0.8386 - val_loss: 0.4847 - val_accuracy: 0.8354\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4665 - accuracy: 0.8398 - val_loss: 0.4960 - val_accuracy: 0.8328\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4626 - accuracy: 0.8399 - val_loss: 0.4802 - val_accuracy: 0.8345\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4619 - accuracy: 0.8413 - val_loss: 0.4888 - val_accuracy: 0.8346\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4594 - accuracy: 0.8416 - val_loss: 0.4877 - val_accuracy: 0.8355\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4564 - accuracy: 0.8431 - val_loss: 0.4884 - val_accuracy: 0.8354\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4554 - accuracy: 0.8423 - val_loss: 0.4794 - val_accuracy: 0.8367\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4532 - accuracy: 0.8438 - val_loss: 0.4774 - val_accuracy: 0.8364\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4537 - accuracy: 0.8428 - val_loss: 0.4850 - val_accuracy: 0.8354\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4509 - accuracy: 0.8449 - val_loss: 0.4768 - val_accuracy: 0.8373\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.4509 - accuracy: 0.8432 - val_loss: 0.4925 - val_accuracy: 0.8368\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4478 - accuracy: 0.8447 - val_loss: 0.4784 - val_accuracy: 0.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff657885860>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "#Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add 1st hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "#Add 2nd hidden layer\n",
    "model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "#Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "MQ7oIymROIVp",
    "outputId": "e8cd511c-aaa5-4f92-d491-f96c2f8b98b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_4 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 92,746\n",
      "Trainable params: 91,178\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "h4ojW6-oOIV2",
    "outputId": "1ad8783d-1e38-4e84-d617-8f92fcd8c799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 1.5962 - accuracy: 0.6105 - val_loss: 1.0645 - val_accuracy: 0.7191\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.8708 - accuracy: 0.7382 - val_loss: 0.7491 - val_accuracy: 0.7567\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.6823 - accuracy: 0.7658 - val_loss: 0.6408 - val_accuracy: 0.7728\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.6019 - accuracy: 0.7861 - val_loss: 0.5835 - val_accuracy: 0.7918\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.5528 - accuracy: 0.8031 - val_loss: 0.5475 - val_accuracy: 0.8045\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.5181 - accuracy: 0.8160 - val_loss: 0.5188 - val_accuracy: 0.8131\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4928 - accuracy: 0.8251 - val_loss: 0.4983 - val_accuracy: 0.8209\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4742 - accuracy: 0.8310 - val_loss: 0.4840 - val_accuracy: 0.8261\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4583 - accuracy: 0.8369 - val_loss: 0.4700 - val_accuracy: 0.8321\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4460 - accuracy: 0.8409 - val_loss: 0.4611 - val_accuracy: 0.8358\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4337 - accuracy: 0.8456 - val_loss: 0.4514 - val_accuracy: 0.8366\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4248 - accuracy: 0.8487 - val_loss: 0.4443 - val_accuracy: 0.8416\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4159 - accuracy: 0.8519 - val_loss: 0.4371 - val_accuracy: 0.8427\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4088 - accuracy: 0.8546 - val_loss: 0.4333 - val_accuracy: 0.8439\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4006 - accuracy: 0.8577 - val_loss: 0.4266 - val_accuracy: 0.8466\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3946 - accuracy: 0.8592 - val_loss: 0.4219 - val_accuracy: 0.8485\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3905 - accuracy: 0.8612 - val_loss: 0.4163 - val_accuracy: 0.8497\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3833 - accuracy: 0.8627 - val_loss: 0.4129 - val_accuracy: 0.8511\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3786 - accuracy: 0.8655 - val_loss: 0.4092 - val_accuracy: 0.8529\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3746 - accuracy: 0.8668 - val_loss: 0.4049 - val_accuracy: 0.8528\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3700 - accuracy: 0.8673 - val_loss: 0.4012 - val_accuracy: 0.8555\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3643 - accuracy: 0.8712 - val_loss: 0.4007 - val_accuracy: 0.8554\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3608 - accuracy: 0.8719 - val_loss: 0.3947 - val_accuracy: 0.8579\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3569 - accuracy: 0.8730 - val_loss: 0.3932 - val_accuracy: 0.8588\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3531 - accuracy: 0.8744 - val_loss: 0.3920 - val_accuracy: 0.8592\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3510 - accuracy: 0.8752 - val_loss: 0.3886 - val_accuracy: 0.8580\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3466 - accuracy: 0.8760 - val_loss: 0.3854 - val_accuracy: 0.8608\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3416 - accuracy: 0.8781 - val_loss: 0.3834 - val_accuracy: 0.8627\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3397 - accuracy: 0.8787 - val_loss: 0.3812 - val_accuracy: 0.8617\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3364 - accuracy: 0.8804 - val_loss: 0.3802 - val_accuracy: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6548778d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=30,\n",
    "          batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R6_ExternalLab_Delhi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

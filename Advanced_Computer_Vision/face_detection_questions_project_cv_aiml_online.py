# -*- coding: utf-8 -*-
"""Face_detection_Questions_Project_CV_AIML_Online.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19vI8vHOjHaVf7cCB0u1e-G3aN4WgDuwI

# Instructions
- Some parts of the code are already done for you
- You need to execute all the cells
- You need to add the code where ever you see `"#### Add your code here ####"`
- Marks are mentioned along with the cells

# Face detection
Task is to predict the boundaries(mask) around the face in a given image.

## Dataset
Faces in images marked with bounding boxes. Have around 500 images with around 1100 faces manually tagged via bounding box.

### Mount Google drive if you are using google colab
- We recommend using Google Colab as you can face memory issues and longer runtimes while running on local
"""

from google.colab import drive
drive.mount('/content/drive')

"""### Change current working directory to project folder (1 mark)"""

import os
import tensorflow as tf
#### Add your code here ####
project_dir = "/content/drive/My Drive/greatlakes/Projects/Advanced_Computer_Vision/Project1/"
os.chdir(project_dir)

"""### Load the "images.npy" file (2 marks)
- This file contains images with details of bounding boxes
"""

import numpy as np
data = np.load('images.npy', allow_pickle=True)

"""### Check one sample from the loaded "images.npy" file  (2 marks)
Hint - print data[10][1]
"""

#### Add your code here ####
print(data[10][1])

"""### Set image dimensions   (1 mark)
- Initialize image height, image width with value: 224
"""

IMAGE_WIDTH = 224
IMAGE_HEIGHT = 224

"""### Create features and labels
- Here feature is the image
- The label is the mask
- Images will be stored in "X_train" array
- Masks will be stored in "masks" array
"""

import cv2
from tensorflow.keras.applications.mobilenet import preprocess_input

masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))
X_train = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))
for index in range(data.shape[0]):
    img = data[index][0]
    img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)
    try:
      img = img[:, :, :3]
    except:
      continue
    X_train[index] = preprocess_input(np.array(img, dtype=np.float32))
    for i in data[index][1]:
        x1 = int(i["points"][0]['x'] * IMAGE_WIDTH)
        x2 = int(i["points"][1]['x'] * IMAGE_WIDTH)
        y1 = int(i["points"][0]['y'] * IMAGE_HEIGHT)
        y2 = int(i["points"][1]['y'] * IMAGE_HEIGHT)
        masks[index][y1:y2, x1:x2] = 1

"""### Print the shape of X_train and mask array  (1 mark)"""

X_train.shape

masks.shape

"""### Print a sample image and image array"""

from matplotlib import pyplot
n = 10
print(X_train[n])
pyplot.imshow(X_train[n])

pyplot.imshow(masks[n])

"""## Create the model (10 marks)
- Add MobileNet as model with below parameter values
  - input_shape: IMAGE_HEIGHT, IMAGE_WIDTH, 3
  - include_top: False
  - alpha: 1.0
  - weights: "imagenet"
- Add UNET architecture layers
  - This is the trickiest part of the project, you need to research and implement it correctly
"""

from tensorflow.keras.applications.mobilenet import MobileNet
from tensorflow.keras.layers import Concatenate, UpSampling2D, Conv2D, Reshape
from tensorflow.keras.models import Model

ALPHA = 1.0 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0). Higher width means more accurate but slower

def create_model(trainable=True):
    model = model = MobileNet(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), include_top=False, alpha=ALPHA,weights="imagenet") # Load pre-trained mobilenet
    for layer in model.layers:
        layer.trainable = trainable

    # Add all the UNET layers here
    
    block1 = model.get_layer("conv_pw_1_relu").output
    block2 = model.get_layer("conv_pw_3_relu").output
    block3 = model.get_layer("conv_pw_5_relu").output
    block4 = model.get_layer("conv_pw_11_relu").output
    block5 = model.get_layer("conv_pw_13_relu").output

    x = Concatenate()([UpSampling2D()(block5), block4])
    x = Concatenate()([UpSampling2D()(x), block3])
    x = Concatenate()([UpSampling2D()(x), block2])
    x = Concatenate()([UpSampling2D()(x), block1])
    x = UpSampling2D()(x)

    x = Conv2D(1, kernel_size=1, activation="sigmoid")(x)
    x = Reshape((IMAGE_WIDTH, IMAGE_HEIGHT))(x)

    return Model(inputs=model.input, outputs=x) #### Add your code here ####

"""### Call the create_model function"""

# Give trainable=False as argument, if you want to freeze lower layers for fast training (but low accuracy)
model = create_model()

# Print summary
model.summary()

"""### Define dice coefficient function (5 marks)
- Create a function to calculate dice coefficient

### Dice Coefficient (F1 Score) Explanation
The Dice Coefficient is 2 * the Area of Overlap divided by the total number of pixels in both images
"""

def dice_coefficient(y_true, y_pred):
    #### Add your code here ####
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)

    return numerator / (denominator + tf.keras.backend.epsilon())

"""### Define loss"""

from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.backend import log, epsilon
def loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())

"""### Compile the model (2 marks)
- Complie the model using below parameters
  - loss: use the loss function defined above
  - optimizers: use Adam optimizer
  - metrics: use dice_coefficient function defined above
"""

#### Add your code here ####
from tensorflow.keras.optimizers import Adam
optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])

"""### Define checkpoint and earlystopping"""

from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
checkpoint = ModelCheckpoint("model-{loss:.2f}.h5", monitor="loss", verbose=1, save_best_only=True,
                             save_weights_only=True, mode="min", period=1)
stop = EarlyStopping(monitor="loss", patience=5, mode="min")
reduce_lr = ReduceLROnPlateau(monitor="loss", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode="min")

"""### Fit the model (2 marks)
- Fit the model using below parameters
  - epochs: you can decide
  - batch_size: 1
  - callbacks: checkpoint, reduce_lr, stop
"""

#### Add your code here ####
EPOCHS = 10
BATCH_SIZE =1
model.fit(X_train, masks, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, callbacks=[checkpoint, reduce_lr, stop], workers=1,
                    use_multiprocessing=False)

"""### Get the predicted mask for a sample image   (3 marks)"""

n = 10
sample_image = X_train[n]
#### Add your code here ####
print(sample_image.shape)
sample_image_reshaped = np.reshape(sample_image,(1,sample_image.shape[0],sample_image.shape[1],sample_image.shape[2]))
print(sample_image_reshaped.shape)
predicted_mask = model.predict(sample_image_reshaped)

print(predicted_mask.shape)
print(masks[n].shape)
predicted_mask_reshaped = np.reshape(predicted_mask,masks[n].shape)
print(predicted_mask_reshaped.shape)

"""### Impose the mask on the image (3 marks)"""

#### Add your code here ####
#pyplot.imshow(masks[n])
pyplot.imshow(predicted_mask_reshaped)

pyplot.imshow(masks[n])


{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqNLP_Project1_Questions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n",
        "\n",
        "\n",
        "### Generate Word Embeddings and retrieve outputs of each layer with Keras based on Classification task\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
        "\n",
        "It is a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n",
        "\n",
        "We willl use the imdb dataset to learn word embeddings as we train our dataset. This dataset contains 25,000 movie reviews from IMDB, labeled with sentiment (positive or negative). \n",
        "\n",
        "\n",
        "\n",
        "### Dataset\n",
        "\n",
        "`from keras.datasets import imdb`\n",
        "\n",
        "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocab size of 10,000.\n",
        "\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "\n",
        "### Aim\n",
        "\n",
        "1. Import test and train data  \n",
        "2. Import the labels ( train and test) \n",
        "3. Get the word index and then Create key value pair for word and word_id. (12.5 points)\n",
        "4. Build a Sequential Model using Keras for Sentiment Classification task. (10 points)\n",
        "5. Report the Accuracy of the model. (5 points)  \n",
        "6. Retrive the output of each layer in keras for a given single test sample from the trained model you built. (2.5 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "#### Usage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "outputId": "a5b1b607-f5f3-4521-8420-60dd115914de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCPC_WN-eCyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0g381XzeCyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6n-uM2eCy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "89229967-66aa-44db-ec24-3172a4626eb6"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    1,   14,   22,   16,   43,  530,\n",
              "        973, 1622, 1385,   65,  458, 4468,   66, 3941,    4,  173,   36,\n",
              "        256,    5,   25,  100,   43,  838,  112,   50,  670,    2,    9,\n",
              "         35,  480,  284,    5,  150,    4,  172,  112,  167,    2,  336,\n",
              "        385,   39,    4,  172, 4536, 1111,   17,  546,   38,   13,  447,\n",
              "          4,  192,   50,   16,    6,  147, 2025,   19,   14,   22,    4,\n",
              "       1920, 4613,  469,    4,   22,   71,   87,   12,   16,   43,  530,\n",
              "         38,   76,   15,   13, 1247,    4,   22,   17,  515,   17,   12,\n",
              "         16,  626,   18,    2,    5,   62,  386,   12,    8,  316,    8,\n",
              "        106,    5,    4, 2223, 5244,   16,  480,   66, 3785,   33,    4,\n",
              "        130,   12,   16,   38,  619,    5,   25,  124,   51,   36,  135,\n",
              "         48,   25, 1415,   33,    6,   22,   12,  215,   28,   77,   52,\n",
              "          5,   14,  407,   16,   82,    2,    8,    4,  107,  117, 5952,\n",
              "         15,  256,    4,    2,    7, 3766,    5,  723,   36,   71,   43,\n",
              "        530,  476,   26,  400,  317,   46,    7,    4,    2, 1029,   13,\n",
              "        104,   88,    4,  381,   15,  297,   98,   32, 2071,   56,   26,\n",
              "        141,    6,  194, 7486,   18,    4,  226,   22,   21,  134,  476,\n",
              "         26,  480,    5,  144,   30, 5535,   18,   51,   36,   28,  224,\n",
              "         92,   25,  104,    4,  226,   65,   16,   38, 1334,   88,   12,\n",
              "         16,  283,    5,   16, 4472,  113,  103,   32,   15,   16, 5345,\n",
              "         19,  178,   32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhMAgaNeCy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "ba520999-914a-4445-b0f2-0523e2db1d41"
      },
      "source": [
        "x_test[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    1,  591,  202,   14,   31,    6,  717,   10,   10,    2,\n",
              "          2,    5,    4,  360,    7,    4,  177, 5760,  394,  354,    4,\n",
              "        123,    9, 1035, 1035, 1035,   10,   10,   13,   92,  124,   89,\n",
              "        488, 7944,  100,   28, 1668,   14,   31,   23,   27, 7479,   29,\n",
              "        220,  468,    8,  124,   14,  286,  170,    8,  157,   46,    5,\n",
              "         27,  239,   16,  179,    2,   38,   32,   25, 7944,  451,  202,\n",
              "         14,    6,  717], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGndu7b-D36f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c5b33df1-2c32-4ad2-efe0-c305d0aed841"
      },
      "source": [
        "import tensorflow as tf\n",
        "word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v) for k,v in word_to_id.items()}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtsFghqRD7NW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a49cf90-0073-4ab6-c8a5-f5040f10df83"
      },
      "source": [
        "word_to_id"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fawn': 34701,\n",
              " 'tsukino': 52006,\n",
              " 'nunnery': 52007,\n",
              " 'sonja': 16816,\n",
              " 'vani': 63951,\n",
              " 'woods': 1408,\n",
              " 'spiders': 16115,\n",
              " 'hanging': 2345,\n",
              " 'woody': 2289,\n",
              " 'trawling': 52008,\n",
              " \"hold's\": 52009,\n",
              " 'comically': 11307,\n",
              " 'localized': 40830,\n",
              " 'disobeying': 30568,\n",
              " \"'royale\": 52010,\n",
              " \"harpo's\": 40831,\n",
              " 'canet': 52011,\n",
              " 'aileen': 19313,\n",
              " 'acurately': 52012,\n",
              " \"diplomat's\": 52013,\n",
              " 'rickman': 25242,\n",
              " 'arranged': 6746,\n",
              " 'rumbustious': 52014,\n",
              " 'familiarness': 52015,\n",
              " \"spider'\": 52016,\n",
              " 'hahahah': 68804,\n",
              " \"wood'\": 52017,\n",
              " 'transvestism': 40833,\n",
              " \"hangin'\": 34702,\n",
              " 'bringing': 2338,\n",
              " 'seamier': 40834,\n",
              " 'wooded': 34703,\n",
              " 'bravora': 52018,\n",
              " 'grueling': 16817,\n",
              " 'wooden': 1636,\n",
              " 'wednesday': 16818,\n",
              " \"'prix\": 52019,\n",
              " 'altagracia': 34704,\n",
              " 'circuitry': 52020,\n",
              " 'crotch': 11585,\n",
              " 'busybody': 57766,\n",
              " \"tart'n'tangy\": 52021,\n",
              " 'burgade': 14129,\n",
              " 'thrace': 52023,\n",
              " \"tom's\": 11038,\n",
              " 'snuggles': 52025,\n",
              " 'francesco': 29114,\n",
              " 'complainers': 52027,\n",
              " 'templarios': 52125,\n",
              " '272': 40835,\n",
              " '273': 52028,\n",
              " 'zaniacs': 52130,\n",
              " '275': 34706,\n",
              " 'consenting': 27631,\n",
              " 'snuggled': 40836,\n",
              " 'inanimate': 15492,\n",
              " 'uality': 52030,\n",
              " 'bronte': 11926,\n",
              " 'errors': 4010,\n",
              " 'dialogs': 3230,\n",
              " \"yomada's\": 52031,\n",
              " \"madman's\": 34707,\n",
              " 'dialoge': 30585,\n",
              " 'usenet': 52033,\n",
              " 'videodrome': 40837,\n",
              " \"kid'\": 26338,\n",
              " 'pawed': 52034,\n",
              " \"'girlfriend'\": 30569,\n",
              " \"'pleasure\": 52035,\n",
              " \"'reloaded'\": 52036,\n",
              " \"kazakos'\": 40839,\n",
              " 'rocque': 52037,\n",
              " 'mailings': 52038,\n",
              " 'brainwashed': 11927,\n",
              " 'mcanally': 16819,\n",
              " \"tom''\": 52039,\n",
              " 'kurupt': 25243,\n",
              " 'affiliated': 21905,\n",
              " 'babaganoosh': 52040,\n",
              " \"noe's\": 40840,\n",
              " 'quart': 40841,\n",
              " 'kids': 359,\n",
              " 'uplifting': 5034,\n",
              " 'controversy': 7093,\n",
              " 'kida': 21906,\n",
              " 'kidd': 23379,\n",
              " \"error'\": 52041,\n",
              " 'neurologist': 52042,\n",
              " 'spotty': 18510,\n",
              " 'cobblers': 30570,\n",
              " 'projection': 9878,\n",
              " 'fastforwarding': 40842,\n",
              " 'sters': 52043,\n",
              " \"eggar's\": 52044,\n",
              " 'etherything': 52045,\n",
              " 'gateshead': 40843,\n",
              " 'airball': 34708,\n",
              " 'unsinkable': 25244,\n",
              " 'stern': 7180,\n",
              " \"cervi's\": 52046,\n",
              " 'dnd': 40844,\n",
              " 'dna': 11586,\n",
              " 'insecurity': 20598,\n",
              " \"'reboot'\": 52047,\n",
              " 'trelkovsky': 11037,\n",
              " 'jaekel': 52048,\n",
              " 'sidebars': 52049,\n",
              " \"sforza's\": 52050,\n",
              " 'distortions': 17633,\n",
              " 'mutinies': 52051,\n",
              " 'sermons': 30602,\n",
              " '7ft': 40846,\n",
              " 'boobage': 52052,\n",
              " \"o'bannon's\": 52053,\n",
              " 'populations': 23380,\n",
              " 'chulak': 52054,\n",
              " 'mesmerize': 27633,\n",
              " 'quinnell': 52055,\n",
              " 'yahoo': 10307,\n",
              " 'meteorologist': 52057,\n",
              " 'beswick': 42577,\n",
              " 'boorman': 15493,\n",
              " 'voicework': 40847,\n",
              " \"ster'\": 52058,\n",
              " 'blustering': 22922,\n",
              " 'hj': 52059,\n",
              " 'intake': 27634,\n",
              " 'morally': 5621,\n",
              " 'jumbling': 40849,\n",
              " 'bowersock': 52060,\n",
              " \"'porky's'\": 52061,\n",
              " 'gershon': 16821,\n",
              " 'ludicrosity': 40850,\n",
              " 'coprophilia': 52062,\n",
              " 'expressively': 40851,\n",
              " \"india's\": 19500,\n",
              " \"post's\": 34710,\n",
              " 'wana': 52063,\n",
              " 'wang': 5283,\n",
              " 'wand': 30571,\n",
              " 'wane': 25245,\n",
              " 'edgeways': 52321,\n",
              " 'titanium': 34711,\n",
              " 'pinta': 40852,\n",
              " 'want': 178,\n",
              " 'pinto': 30572,\n",
              " 'whoopdedoodles': 52065,\n",
              " 'tchaikovsky': 21908,\n",
              " 'travel': 2103,\n",
              " \"'victory'\": 52066,\n",
              " 'copious': 11928,\n",
              " 'gouge': 22433,\n",
              " \"chapters'\": 52067,\n",
              " 'barbra': 6702,\n",
              " 'uselessness': 30573,\n",
              " \"wan'\": 52068,\n",
              " 'assimilated': 27635,\n",
              " 'petiot': 16116,\n",
              " 'most\\x85and': 52069,\n",
              " 'dinosaurs': 3930,\n",
              " 'wrong': 352,\n",
              " 'seda': 52070,\n",
              " 'stollen': 52071,\n",
              " 'sentencing': 34712,\n",
              " 'ouroboros': 40853,\n",
              " 'assimilates': 40854,\n",
              " 'colorfully': 40855,\n",
              " 'glenne': 27636,\n",
              " 'dongen': 52072,\n",
              " 'subplots': 4760,\n",
              " 'kiloton': 52073,\n",
              " 'chandon': 23381,\n",
              " \"effect'\": 34713,\n",
              " 'snugly': 27637,\n",
              " 'kuei': 40856,\n",
              " 'welcomed': 9092,\n",
              " 'dishonor': 30071,\n",
              " 'concurrence': 52075,\n",
              " 'stoicism': 23382,\n",
              " \"guys'\": 14896,\n",
              " \"beroemd'\": 52077,\n",
              " 'butcher': 6703,\n",
              " \"melfi's\": 40857,\n",
              " 'aargh': 30623,\n",
              " 'playhouse': 20599,\n",
              " 'wickedly': 11308,\n",
              " 'fit': 1180,\n",
              " 'labratory': 52078,\n",
              " 'lifeline': 40859,\n",
              " 'screaming': 1927,\n",
              " 'fix': 4287,\n",
              " 'cineliterate': 52079,\n",
              " 'fic': 52080,\n",
              " 'fia': 52081,\n",
              " 'fig': 34714,\n",
              " 'fmvs': 52082,\n",
              " 'fie': 52083,\n",
              " 'reentered': 52084,\n",
              " 'fin': 30574,\n",
              " 'doctresses': 52085,\n",
              " 'fil': 52086,\n",
              " 'zucker': 12606,\n",
              " 'ached': 31931,\n",
              " 'counsil': 52088,\n",
              " 'paterfamilias': 52089,\n",
              " 'songwriter': 13885,\n",
              " 'shivam': 34715,\n",
              " 'hurting': 9654,\n",
              " 'effects': 299,\n",
              " 'slauther': 52090,\n",
              " \"'flame'\": 52091,\n",
              " 'sommerset': 52092,\n",
              " 'interwhined': 52093,\n",
              " 'whacking': 27638,\n",
              " 'bartok': 52094,\n",
              " 'barton': 8775,\n",
              " 'frewer': 21909,\n",
              " \"fi'\": 52095,\n",
              " 'ingrid': 6192,\n",
              " 'stribor': 30575,\n",
              " 'approporiately': 52096,\n",
              " 'wobblyhand': 52097,\n",
              " 'tantalisingly': 52098,\n",
              " 'ankylosaurus': 52099,\n",
              " 'parasites': 17634,\n",
              " 'childen': 52100,\n",
              " \"jenkins'\": 52101,\n",
              " 'metafiction': 52102,\n",
              " 'golem': 17635,\n",
              " 'indiscretion': 40860,\n",
              " \"reeves'\": 23383,\n",
              " \"inamorata's\": 57781,\n",
              " 'brittannica': 52104,\n",
              " 'adapt': 7916,\n",
              " \"russo's\": 30576,\n",
              " 'guitarists': 48246,\n",
              " 'abbott': 10553,\n",
              " 'abbots': 40861,\n",
              " 'lanisha': 17649,\n",
              " 'magickal': 40863,\n",
              " 'mattter': 52105,\n",
              " \"'willy\": 52106,\n",
              " 'pumpkins': 34716,\n",
              " 'stuntpeople': 52107,\n",
              " 'estimate': 30577,\n",
              " 'ugghhh': 40864,\n",
              " 'gameplay': 11309,\n",
              " \"wern't\": 52108,\n",
              " \"n'sync\": 40865,\n",
              " 'sickeningly': 16117,\n",
              " 'chiara': 40866,\n",
              " 'disturbed': 4011,\n",
              " 'portmanteau': 40867,\n",
              " 'ineffectively': 52109,\n",
              " \"duchonvey's\": 82143,\n",
              " \"nasty'\": 37519,\n",
              " 'purpose': 1285,\n",
              " 'lazers': 52112,\n",
              " 'lightened': 28105,\n",
              " 'kaliganj': 52113,\n",
              " 'popularism': 52114,\n",
              " \"damme's\": 18511,\n",
              " 'stylistics': 30578,\n",
              " 'mindgaming': 52115,\n",
              " 'spoilerish': 46449,\n",
              " \"'corny'\": 52117,\n",
              " 'boerner': 34718,\n",
              " 'olds': 6792,\n",
              " 'bakelite': 52118,\n",
              " 'renovated': 27639,\n",
              " 'forrester': 27640,\n",
              " \"lumiere's\": 52119,\n",
              " 'gaskets': 52024,\n",
              " 'needed': 884,\n",
              " 'smight': 34719,\n",
              " 'master': 1297,\n",
              " \"edie's\": 25905,\n",
              " 'seeber': 40868,\n",
              " 'hiya': 52120,\n",
              " 'fuzziness': 52121,\n",
              " 'genesis': 14897,\n",
              " 'rewards': 12607,\n",
              " 'enthrall': 30579,\n",
              " \"'about\": 40869,\n",
              " \"recollection's\": 52122,\n",
              " 'mutilated': 11039,\n",
              " 'fatherlands': 52123,\n",
              " \"fischer's\": 52124,\n",
              " 'positively': 5399,\n",
              " '270': 34705,\n",
              " 'ahmed': 34720,\n",
              " 'zatoichi': 9836,\n",
              " 'bannister': 13886,\n",
              " 'anniversaries': 52127,\n",
              " \"helm's\": 30580,\n",
              " \"'work'\": 52128,\n",
              " 'exclaimed': 34721,\n",
              " \"'unfunny'\": 52129,\n",
              " '274': 52029,\n",
              " 'feeling': 544,\n",
              " \"wanda's\": 52131,\n",
              " 'dolan': 33266,\n",
              " '278': 52133,\n",
              " 'peacoat': 52134,\n",
              " 'brawny': 40870,\n",
              " 'mishra': 40871,\n",
              " 'worlders': 40872,\n",
              " 'protags': 52135,\n",
              " 'skullcap': 52136,\n",
              " 'dastagir': 57596,\n",
              " 'affairs': 5622,\n",
              " 'wholesome': 7799,\n",
              " 'hymen': 52137,\n",
              " 'paramedics': 25246,\n",
              " 'unpersons': 52138,\n",
              " 'heavyarms': 52139,\n",
              " 'affaire': 52140,\n",
              " 'coulisses': 52141,\n",
              " 'hymer': 40873,\n",
              " 'kremlin': 52142,\n",
              " 'shipments': 30581,\n",
              " 'pixilated': 52143,\n",
              " \"'00s\": 30582,\n",
              " 'diminishing': 18512,\n",
              " 'cinematic': 1357,\n",
              " 'resonates': 14898,\n",
              " 'simplify': 40874,\n",
              " \"nature'\": 40875,\n",
              " 'temptresses': 40876,\n",
              " 'reverence': 16822,\n",
              " 'resonated': 19502,\n",
              " 'dailey': 34722,\n",
              " '2\\x85': 52144,\n",
              " 'treize': 27641,\n",
              " 'majo': 52145,\n",
              " 'kiya': 21910,\n",
              " 'woolnough': 52146,\n",
              " 'thanatos': 39797,\n",
              " 'sandoval': 35731,\n",
              " 'dorama': 40879,\n",
              " \"o'shaughnessy\": 52147,\n",
              " 'tech': 4988,\n",
              " 'fugitives': 32018,\n",
              " 'teck': 30583,\n",
              " \"'e'\": 76125,\n",
              " 'doesn’t': 40881,\n",
              " 'purged': 52149,\n",
              " 'saying': 657,\n",
              " \"martians'\": 41095,\n",
              " 'norliss': 23418,\n",
              " 'dickey': 27642,\n",
              " 'dicker': 52152,\n",
              " \"'sependipity\": 52153,\n",
              " 'padded': 8422,\n",
              " 'ordell': 57792,\n",
              " \"sturges'\": 40882,\n",
              " 'independentcritics': 52154,\n",
              " 'tempted': 5745,\n",
              " \"atkinson's\": 34724,\n",
              " 'hounded': 25247,\n",
              " 'apace': 52155,\n",
              " 'clicked': 15494,\n",
              " \"'humor'\": 30584,\n",
              " \"martino's\": 17177,\n",
              " \"'supporting\": 52156,\n",
              " 'warmongering': 52032,\n",
              " \"zemeckis's\": 34725,\n",
              " 'lube': 21911,\n",
              " 'shocky': 52157,\n",
              " 'plate': 7476,\n",
              " 'plata': 40883,\n",
              " 'sturgess': 40884,\n",
              " \"nerds'\": 40885,\n",
              " 'plato': 20600,\n",
              " 'plath': 34726,\n",
              " 'platt': 40886,\n",
              " 'mcnab': 52159,\n",
              " 'clumsiness': 27643,\n",
              " 'altogether': 3899,\n",
              " 'massacring': 42584,\n",
              " 'bicenntinial': 52160,\n",
              " 'skaal': 40887,\n",
              " 'droning': 14360,\n",
              " 'lds': 8776,\n",
              " 'jaguar': 21912,\n",
              " \"cale's\": 34727,\n",
              " 'nicely': 1777,\n",
              " 'mummy': 4588,\n",
              " \"lot's\": 18513,\n",
              " 'patch': 10086,\n",
              " 'kerkhof': 50202,\n",
              " \"leader's\": 52161,\n",
              " \"'movie\": 27644,\n",
              " 'uncomfirmed': 52162,\n",
              " 'heirloom': 40888,\n",
              " 'wrangle': 47360,\n",
              " 'emotion\\x85': 52163,\n",
              " \"'stargate'\": 52164,\n",
              " 'pinoy': 40889,\n",
              " 'conchatta': 40890,\n",
              " 'broeke': 41128,\n",
              " 'advisedly': 40891,\n",
              " \"barker's\": 17636,\n",
              " 'descours': 52166,\n",
              " 'lots': 772,\n",
              " 'lotr': 9259,\n",
              " 'irs': 9879,\n",
              " 'lott': 52167,\n",
              " 'xvi': 40892,\n",
              " 'irk': 34728,\n",
              " 'irl': 52168,\n",
              " 'ira': 6887,\n",
              " 'belzer': 21913,\n",
              " 'irc': 52169,\n",
              " 'ire': 27645,\n",
              " 'requisites': 40893,\n",
              " 'discipline': 7693,\n",
              " 'lyoko': 52961,\n",
              " 'extend': 11310,\n",
              " 'nature': 873,\n",
              " \"'dickie'\": 52170,\n",
              " 'optimist': 40894,\n",
              " 'lapping': 30586,\n",
              " 'superficial': 3900,\n",
              " 'vestment': 52171,\n",
              " 'extent': 2823,\n",
              " 'tendons': 52172,\n",
              " \"heller's\": 52173,\n",
              " 'quagmires': 52174,\n",
              " 'miyako': 52175,\n",
              " 'moocow': 20601,\n",
              " \"coles'\": 52176,\n",
              " 'lookit': 40895,\n",
              " 'ravenously': 52177,\n",
              " 'levitating': 40896,\n",
              " 'perfunctorily': 52178,\n",
              " 'lookin': 30587,\n",
              " \"lot'\": 40898,\n",
              " 'lookie': 52179,\n",
              " 'fearlessly': 34870,\n",
              " 'libyan': 52181,\n",
              " 'fondles': 40899,\n",
              " 'gopher': 35714,\n",
              " 'wearying': 40901,\n",
              " \"nz's\": 52182,\n",
              " 'minuses': 27646,\n",
              " 'puposelessly': 52183,\n",
              " 'shandling': 52184,\n",
              " 'decapitates': 31268,\n",
              " 'humming': 11929,\n",
              " \"'nother\": 40902,\n",
              " 'smackdown': 21914,\n",
              " 'underdone': 30588,\n",
              " 'frf': 40903,\n",
              " 'triviality': 52185,\n",
              " 'fro': 25248,\n",
              " 'bothers': 8777,\n",
              " \"'kensington\": 52186,\n",
              " 'much': 73,\n",
              " 'muco': 34730,\n",
              " 'wiseguy': 22615,\n",
              " \"richie's\": 27648,\n",
              " 'tonino': 40904,\n",
              " 'unleavened': 52187,\n",
              " 'fry': 11587,\n",
              " \"'tv'\": 40905,\n",
              " 'toning': 40906,\n",
              " 'obese': 14361,\n",
              " 'sensationalized': 30589,\n",
              " 'spiv': 40907,\n",
              " 'spit': 6259,\n",
              " 'arkin': 7364,\n",
              " 'charleton': 21915,\n",
              " 'jeon': 16823,\n",
              " 'boardroom': 21916,\n",
              " 'doubts': 4989,\n",
              " 'spin': 3084,\n",
              " 'hepo': 53083,\n",
              " 'wildcat': 27649,\n",
              " 'venoms': 10584,\n",
              " 'misconstrues': 52191,\n",
              " 'mesmerising': 18514,\n",
              " 'misconstrued': 40908,\n",
              " 'rescinds': 52192,\n",
              " 'prostrate': 52193,\n",
              " 'majid': 40909,\n",
              " 'climbed': 16479,\n",
              " 'canoeing': 34731,\n",
              " 'majin': 52195,\n",
              " 'animie': 57804,\n",
              " 'sylke': 40910,\n",
              " 'conditioned': 14899,\n",
              " 'waddell': 40911,\n",
              " '3\\x85': 52196,\n",
              " 'hyperdrive': 41188,\n",
              " 'conditioner': 34732,\n",
              " 'bricklayer': 53153,\n",
              " 'hong': 2576,\n",
              " 'memoriam': 52198,\n",
              " 'inventively': 30592,\n",
              " \"levant's\": 25249,\n",
              " 'portobello': 20638,\n",
              " 'remand': 52200,\n",
              " 'mummified': 19504,\n",
              " 'honk': 27650,\n",
              " 'spews': 19505,\n",
              " 'visitations': 40912,\n",
              " 'mummifies': 52201,\n",
              " 'cavanaugh': 25250,\n",
              " 'zeon': 23385,\n",
              " \"jungle's\": 40913,\n",
              " 'viertel': 34733,\n",
              " 'frenchmen': 27651,\n",
              " 'torpedoes': 52202,\n",
              " 'schlessinger': 52203,\n",
              " 'torpedoed': 34734,\n",
              " 'blister': 69876,\n",
              " 'cinefest': 52204,\n",
              " 'furlough': 34735,\n",
              " 'mainsequence': 52205,\n",
              " 'mentors': 40914,\n",
              " 'academic': 9094,\n",
              " 'stillness': 20602,\n",
              " 'academia': 40915,\n",
              " 'lonelier': 52206,\n",
              " 'nibby': 52207,\n",
              " \"losers'\": 52208,\n",
              " 'cineastes': 40916,\n",
              " 'corporate': 4449,\n",
              " 'massaging': 40917,\n",
              " 'bellow': 30593,\n",
              " 'absurdities': 19506,\n",
              " 'expetations': 53241,\n",
              " 'nyfiken': 40918,\n",
              " 'mehras': 75638,\n",
              " 'lasse': 52209,\n",
              " 'visability': 52210,\n",
              " 'militarily': 33946,\n",
              " \"elder'\": 52211,\n",
              " 'gainsbourg': 19023,\n",
              " 'hah': 20603,\n",
              " 'hai': 13420,\n",
              " 'haj': 34736,\n",
              " 'hak': 25251,\n",
              " 'hal': 4311,\n",
              " 'ham': 4892,\n",
              " 'duffer': 53259,\n",
              " 'haa': 52213,\n",
              " 'had': 66,\n",
              " 'advancement': 11930,\n",
              " 'hag': 16825,\n",
              " \"hand'\": 25252,\n",
              " 'hay': 13421,\n",
              " 'mcnamara': 20604,\n",
              " \"mozart's\": 52214,\n",
              " 'duffel': 30731,\n",
              " 'haq': 30594,\n",
              " 'har': 13887,\n",
              " 'has': 44,\n",
              " 'hat': 2401,\n",
              " 'hav': 40919,\n",
              " 'haw': 30595,\n",
              " 'figtings': 52215,\n",
              " 'elders': 15495,\n",
              " 'underpanted': 52216,\n",
              " 'pninson': 52217,\n",
              " 'unequivocally': 27652,\n",
              " \"barbara's\": 23673,\n",
              " \"bello'\": 52219,\n",
              " 'indicative': 12997,\n",
              " 'yawnfest': 40920,\n",
              " 'hexploitation': 52220,\n",
              " \"loder's\": 52221,\n",
              " 'sleuthing': 27653,\n",
              " \"justin's\": 32622,\n",
              " \"'ball\": 52222,\n",
              " \"'summer\": 52223,\n",
              " \"'demons'\": 34935,\n",
              " \"mormon's\": 52225,\n",
              " \"laughton's\": 34737,\n",
              " 'debell': 52226,\n",
              " 'shipyard': 39724,\n",
              " 'unabashedly': 30597,\n",
              " 'disks': 40401,\n",
              " 'crowd': 2290,\n",
              " 'crowe': 10087,\n",
              " \"vancouver's\": 56434,\n",
              " 'mosques': 34738,\n",
              " 'crown': 6627,\n",
              " 'culpas': 52227,\n",
              " 'crows': 27654,\n",
              " 'surrell': 53344,\n",
              " 'flowless': 52229,\n",
              " 'sheirk': 52230,\n",
              " \"'three\": 40923,\n",
              " \"peterson'\": 52231,\n",
              " 'ooverall': 52232,\n",
              " 'perchance': 40924,\n",
              " 'bottom': 1321,\n",
              " 'chabert': 53363,\n",
              " 'sneha': 52233,\n",
              " 'inhuman': 13888,\n",
              " 'ichii': 52234,\n",
              " 'ursla': 52235,\n",
              " 'completly': 30598,\n",
              " 'moviedom': 40925,\n",
              " 'raddick': 52236,\n",
              " 'brundage': 51995,\n",
              " 'brigades': 40926,\n",
              " 'starring': 1181,\n",
              " \"'goal'\": 52237,\n",
              " 'caskets': 52238,\n",
              " 'willcock': 52239,\n",
              " \"threesome's\": 52240,\n",
              " \"mosque'\": 52241,\n",
              " \"cover's\": 52242,\n",
              " 'spaceships': 17637,\n",
              " 'anomalous': 40927,\n",
              " 'ptsd': 27655,\n",
              " 'shirdan': 52243,\n",
              " 'obscenity': 21962,\n",
              " 'lemmings': 30599,\n",
              " 'duccio': 30600,\n",
              " \"levene's\": 52244,\n",
              " \"'gorby'\": 52245,\n",
              " \"teenager's\": 25255,\n",
              " 'marshall': 5340,\n",
              " 'honeymoon': 9095,\n",
              " 'shoots': 3231,\n",
              " 'despised': 12258,\n",
              " 'okabasho': 52246,\n",
              " 'fabric': 8289,\n",
              " 'cannavale': 18515,\n",
              " 'raped': 3537,\n",
              " \"tutt's\": 52247,\n",
              " 'grasping': 17638,\n",
              " 'despises': 18516,\n",
              " \"thief's\": 40928,\n",
              " 'rapes': 8926,\n",
              " 'raper': 52248,\n",
              " \"eyre'\": 27656,\n",
              " 'walchek': 52249,\n",
              " \"elmo's\": 23386,\n",
              " 'perfumes': 40929,\n",
              " 'spurting': 21918,\n",
              " \"exposition'\\x85\": 52250,\n",
              " 'denoting': 52251,\n",
              " 'thesaurus': 34740,\n",
              " \"shoot'\": 40930,\n",
              " 'bonejack': 49759,\n",
              " 'simpsonian': 52253,\n",
              " 'hebetude': 30601,\n",
              " \"hallow's\": 34741,\n",
              " 'desperation\\x85': 52254,\n",
              " 'incinerator': 34742,\n",
              " 'congratulations': 10308,\n",
              " 'humbled': 52255,\n",
              " \"else's\": 5924,\n",
              " 'trelkovski': 40845,\n",
              " \"rape'\": 52256,\n",
              " \"'chapters'\": 59386,\n",
              " '1600s': 52257,\n",
              " 'martian': 7253,\n",
              " 'nicest': 25256,\n",
              " 'eyred': 52259,\n",
              " 'passenger': 9457,\n",
              " 'disgrace': 6041,\n",
              " 'moderne': 52260,\n",
              " 'barrymore': 5120,\n",
              " 'yankovich': 52261,\n",
              " 'moderns': 40931,\n",
              " 'studliest': 52262,\n",
              " 'bedsheet': 52263,\n",
              " 'decapitation': 14900,\n",
              " 'slurring': 52264,\n",
              " \"'nunsploitation'\": 52265,\n",
              " \"'character'\": 34743,\n",
              " 'cambodia': 9880,\n",
              " 'rebelious': 52266,\n",
              " 'pasadena': 27657,\n",
              " 'crowne': 40932,\n",
              " \"'bedchamber\": 52267,\n",
              " 'conjectural': 52268,\n",
              " 'appologize': 52269,\n",
              " 'halfassing': 52270,\n",
              " 'paycheque': 57816,\n",
              " 'palms': 20606,\n",
              " \"'islands\": 52271,\n",
              " 'hawked': 40933,\n",
              " 'palme': 21919,\n",
              " 'conservatively': 40934,\n",
              " 'larp': 64007,\n",
              " 'palma': 5558,\n",
              " 'smelling': 21920,\n",
              " 'aragorn': 12998,\n",
              " 'hawker': 52272,\n",
              " 'hawkes': 52273,\n",
              " 'explosions': 3975,\n",
              " 'loren': 8059,\n",
              " \"pyle's\": 52274,\n",
              " 'shootout': 6704,\n",
              " \"mike's\": 18517,\n",
              " \"driscoll's\": 52275,\n",
              " 'cogsworth': 40935,\n",
              " \"britian's\": 52276,\n",
              " 'childs': 34744,\n",
              " \"portrait's\": 52277,\n",
              " 'chain': 3626,\n",
              " 'whoever': 2497,\n",
              " 'puttered': 52278,\n",
              " 'childe': 52279,\n",
              " 'maywether': 52280,\n",
              " 'chair': 3036,\n",
              " \"rance's\": 52281,\n",
              " 'machu': 34745,\n",
              " 'ballet': 4517,\n",
              " 'grapples': 34746,\n",
              " 'summerize': 76152,\n",
              " 'freelance': 30603,\n",
              " \"andrea's\": 52283,\n",
              " '\\x91very': 52284,\n",
              " 'coolidge': 45879,\n",
              " 'mache': 18518,\n",
              " 'balled': 52285,\n",
              " 'grappled': 40937,\n",
              " 'macha': 18519,\n",
              " 'underlining': 21921,\n",
              " 'macho': 5623,\n",
              " 'oversight': 19507,\n",
              " 'machi': 25257,\n",
              " 'verbally': 11311,\n",
              " 'tenacious': 21922,\n",
              " 'windshields': 40938,\n",
              " 'paychecks': 18557,\n",
              " 'jerk': 3396,\n",
              " \"good'\": 11931,\n",
              " 'prancer': 34748,\n",
              " 'prances': 21923,\n",
              " 'olympus': 52286,\n",
              " 'lark': 21924,\n",
              " 'embark': 10785,\n",
              " 'gloomy': 7365,\n",
              " 'jehaan': 52287,\n",
              " 'turaqui': 52288,\n",
              " \"child'\": 20607,\n",
              " 'locked': 2894,\n",
              " 'pranced': 52289,\n",
              " 'exact': 2588,\n",
              " 'unattuned': 52290,\n",
              " 'minute': 783,\n",
              " 'skewed': 16118,\n",
              " 'hodgins': 40940,\n",
              " 'skewer': 34749,\n",
              " 'think\\x85': 52291,\n",
              " 'rosenstein': 38765,\n",
              " 'helmit': 52292,\n",
              " 'wrestlemanias': 34750,\n",
              " 'hindered': 16826,\n",
              " \"martha's\": 30604,\n",
              " 'cheree': 52293,\n",
              " \"pluckin'\": 52294,\n",
              " 'ogles': 40941,\n",
              " 'heavyweight': 11932,\n",
              " 'aada': 82190,\n",
              " 'chopping': 11312,\n",
              " 'strongboy': 61534,\n",
              " 'hegemonic': 41342,\n",
              " 'adorns': 40942,\n",
              " 'xxth': 41346,\n",
              " 'nobuhiro': 34751,\n",
              " 'capitães': 52298,\n",
              " 'kavogianni': 52299,\n",
              " 'antwerp': 13422,\n",
              " 'celebrated': 6538,\n",
              " 'roarke': 52300,\n",
              " 'baggins': 40943,\n",
              " 'cheeseburgers': 31270,\n",
              " 'matras': 52301,\n",
              " \"nineties'\": 52302,\n",
              " \"'craig'\": 52303,\n",
              " 'celebrates': 12999,\n",
              " 'unintentionally': 3383,\n",
              " 'drafted': 14362,\n",
              " 'climby': 52304,\n",
              " '303': 52305,\n",
              " 'oldies': 18520,\n",
              " 'climbs': 9096,\n",
              " 'honour': 9655,\n",
              " 'plucking': 34752,\n",
              " '305': 30074,\n",
              " 'address': 5514,\n",
              " 'menjou': 40944,\n",
              " \"'freak'\": 42592,\n",
              " 'dwindling': 19508,\n",
              " 'benson': 9458,\n",
              " 'white’s': 52307,\n",
              " 'shamelessness': 40945,\n",
              " 'impacted': 21925,\n",
              " 'upatz': 52308,\n",
              " 'cusack': 3840,\n",
              " \"flavia's\": 37567,\n",
              " 'effette': 52309,\n",
              " 'influx': 34753,\n",
              " 'boooooooo': 52310,\n",
              " 'dimitrova': 52311,\n",
              " 'houseman': 13423,\n",
              " 'bigas': 25259,\n",
              " 'boylen': 52312,\n",
              " 'phillipenes': 52313,\n",
              " 'fakery': 40946,\n",
              " \"grandpa's\": 27658,\n",
              " 'darnell': 27659,\n",
              " 'undergone': 19509,\n",
              " 'handbags': 52315,\n",
              " 'perished': 21926,\n",
              " 'pooped': 37778,\n",
              " 'vigour': 27660,\n",
              " 'opposed': 3627,\n",
              " 'etude': 52316,\n",
              " \"caine's\": 11799,\n",
              " 'doozers': 52317,\n",
              " 'photojournals': 34754,\n",
              " 'perishes': 52318,\n",
              " 'constrains': 34755,\n",
              " 'migenes': 40948,\n",
              " 'consoled': 30605,\n",
              " 'alastair': 16827,\n",
              " 'wvs': 52319,\n",
              " 'ooooooh': 52320,\n",
              " 'approving': 34756,\n",
              " 'consoles': 40949,\n",
              " 'disparagement': 52064,\n",
              " 'futureistic': 52322,\n",
              " 'rebounding': 52323,\n",
              " \"'date\": 52324,\n",
              " 'gregoire': 52325,\n",
              " 'rutherford': 21927,\n",
              " 'americanised': 34757,\n",
              " 'novikov': 82196,\n",
              " 'following': 1042,\n",
              " 'munroe': 34758,\n",
              " \"morita'\": 52326,\n",
              " 'christenssen': 52327,\n",
              " 'oatmeal': 23106,\n",
              " 'fossey': 25260,\n",
              " 'livered': 40950,\n",
              " 'listens': 13000,\n",
              " \"'marci\": 76164,\n",
              " \"otis's\": 52330,\n",
              " 'thanking': 23387,\n",
              " 'maude': 16019,\n",
              " 'extensions': 34759,\n",
              " 'ameteurish': 52332,\n",
              " \"commender's\": 52333,\n",
              " 'agricultural': 27661,\n",
              " 'convincingly': 4518,\n",
              " 'fueled': 17639,\n",
              " 'mahattan': 54014,\n",
              " \"paris's\": 40952,\n",
              " 'vulkan': 52336,\n",
              " 'stapes': 52337,\n",
              " 'odysessy': 52338,\n",
              " 'harmon': 12259,\n",
              " 'surfing': 4252,\n",
              " 'halloran': 23494,\n",
              " 'unbelieveably': 49580,\n",
              " \"'offed'\": 52339,\n",
              " 'quadrant': 30607,\n",
              " 'inhabiting': 19510,\n",
              " 'nebbish': 34760,\n",
              " 'forebears': 40953,\n",
              " 'skirmish': 34761,\n",
              " 'ocassionally': 52340,\n",
              " \"'resist\": 52341,\n",
              " 'impactful': 21928,\n",
              " 'spicier': 52342,\n",
              " 'touristy': 40954,\n",
              " \"'football'\": 52343,\n",
              " 'webpage': 40955,\n",
              " 'exurbia': 52345,\n",
              " 'jucier': 52346,\n",
              " 'professors': 14901,\n",
              " 'structuring': 34762,\n",
              " 'jig': 30608,\n",
              " 'overlord': 40956,\n",
              " 'disconnect': 25261,\n",
              " 'sniffle': 82201,\n",
              " 'slimeball': 40957,\n",
              " 'jia': 40958,\n",
              " 'milked': 16828,\n",
              " 'banjoes': 40959,\n",
              " 'jim': 1237,\n",
              " 'workforces': 52348,\n",
              " 'jip': 52349,\n",
              " 'rotweiller': 52350,\n",
              " 'mundaneness': 34763,\n",
              " \"'ninja'\": 52351,\n",
              " \"dead'\": 11040,\n",
              " \"cipriani's\": 40960,\n",
              " 'modestly': 20608,\n",
              " \"professor'\": 52352,\n",
              " 'shacked': 40961,\n",
              " 'bashful': 34764,\n",
              " 'sorter': 23388,\n",
              " 'overpowering': 16120,\n",
              " 'workmanlike': 18521,\n",
              " 'henpecked': 27662,\n",
              " 'sorted': 18522,\n",
              " \"jōb's\": 52354,\n",
              " \"'always\": 52355,\n",
              " \"'baptists\": 34765,\n",
              " 'dreamcatchers': 52356,\n",
              " \"'silence'\": 52357,\n",
              " 'hickory': 21929,\n",
              " 'fun\\x97yet': 52358,\n",
              " 'breakumentary': 52359,\n",
              " 'didn': 15496,\n",
              " 'didi': 52360,\n",
              " 'pealing': 52361,\n",
              " 'dispite': 40962,\n",
              " \"italy's\": 25262,\n",
              " 'instability': 21930,\n",
              " 'quarter': 6539,\n",
              " 'quartet': 12608,\n",
              " 'padmé': 52362,\n",
              " \"'bleedmedry\": 52363,\n",
              " 'pahalniuk': 52364,\n",
              " 'honduras': 52365,\n",
              " 'bursting': 10786,\n",
              " \"pablo's\": 41465,\n",
              " 'irremediably': 52367,\n",
              " 'presages': 40963,\n",
              " 'bowlegged': 57832,\n",
              " 'dalip': 65183,\n",
              " 'entering': 6260,\n",
              " 'newsradio': 76172,\n",
              " 'presaged': 54150,\n",
              " \"giallo's\": 27663,\n",
              " 'bouyant': 40964,\n",
              " 'amerterish': 52368,\n",
              " 'rajni': 18523,\n",
              " 'leeves': 30610,\n",
              " 'macauley': 34767,\n",
              " 'seriously': 612,\n",
              " 'sugercoma': 52369,\n",
              " 'grimstead': 52370,\n",
              " \"'fairy'\": 52371,\n",
              " 'zenda': 30611,\n",
              " \"'twins'\": 52372,\n",
              " 'realisation': 17640,\n",
              " 'highsmith': 27664,\n",
              " 'raunchy': 7817,\n",
              " 'incentives': 40965,\n",
              " 'flatson': 52374,\n",
              " 'snooker': 35097,\n",
              " 'crazies': 16829,\n",
              " 'crazier': 14902,\n",
              " 'grandma': 7094,\n",
              " 'napunsaktha': 52375,\n",
              " 'workmanship': 30612,\n",
              " 'reisner': 52376,\n",
              " \"sanford's\": 61306,\n",
              " '\\x91doña': 52377,\n",
              " 'modest': 6108,\n",
              " \"everything's\": 19153,\n",
              " 'hamer': 40966,\n",
              " \"couldn't'\": 52379,\n",
              " 'quibble': 13001,\n",
              " 'socking': 52380,\n",
              " 'tingler': 21931,\n",
              " 'gutman': 52381,\n",
              " 'lachlan': 40967,\n",
              " 'tableaus': 52382,\n",
              " 'headbanger': 52383,\n",
              " 'spoken': 2847,\n",
              " 'cerebrally': 34768,\n",
              " \"'road\": 23490,\n",
              " 'tableaux': 21932,\n",
              " \"proust's\": 40968,\n",
              " 'periodical': 40969,\n",
              " \"shoveller's\": 52385,\n",
              " 'tamara': 25263,\n",
              " 'affords': 17641,\n",
              " 'concert': 3249,\n",
              " \"yara's\": 87955,\n",
              " 'someome': 52386,\n",
              " 'lingering': 8424,\n",
              " \"abraham's\": 41511,\n",
              " 'beesley': 34769,\n",
              " 'cherbourg': 34770,\n",
              " 'kagan': 28624,\n",
              " 'snatch': 9097,\n",
              " \"miyazaki's\": 9260,\n",
              " 'absorbs': 25264,\n",
              " \"koltai's\": 40970,\n",
              " 'tingled': 64027,\n",
              " 'crossroads': 19511,\n",
              " 'rehab': 16121,\n",
              " 'falworth': 52389,\n",
              " 'sequals': 52390,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybtUgUReCy8",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OLM4eBeCy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "8244d833-27fe-49f5-fad2-85e76141b957"
      },
      "source": [
        "import glob\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim=10000,\n",
        "        output_dim=100,\n",
        "        weights=None,\n",
        "        trainable=True))\n",
        "\n",
        "# Recurrent layer\n",
        "model.add(\n",
        "    LSTM(\n",
        "        64, return_sequences=False, dropout=0.1,\n",
        "        recurrent_dropout=0.1))\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout for regularization\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,046,465\n",
            "Trainable params: 1,046,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxNDNhrseCzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "82781d36-f96d-49ee-be28-5611739983c6"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=64, epochs=3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "25000/25000 [==============================] - 238s 10ms/step - loss: 7.9712 - acc: 0.5000\n",
            "Epoch 2/3\n",
            "25000/25000 [==============================] - 231s 9ms/step - loss: 7.9712 - acc: 0.5000\n",
            "Epoch 3/3\n",
            "25000/25000 [==============================] - 232s 9ms/step - loss: 7.9712 - acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fae5c960dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3CSVVPPeCzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igq8Qm8GeCzG",
        "colab_type": "text"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AqOnLa2eCzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def layer_outs_for_single_instance(model, instance):\n",
        "    outputs = [layer.output for layer in model.layers]                  # all layer outputs\n",
        "    function = K.function([model.input, K.learning_phase()], outputs)   # evaluation function\n",
        "    \n",
        "    if instance.any():\n",
        "        layer_outs = function([np.array([instance,]), 1.])\n",
        "        print('_'*75)\n",
        "        for idx, out in enumerate(layer_outs):\n",
        "            print('\\033[1mLayer# :', idx + 1)\n",
        "            print('\\033[1mName   :', model.layers[idx].name)\n",
        "            print('\\033[1mShape  : ' + str(out.shape) + '\\033[0m')\n",
        "            print(out)\n",
        "            print('_'*75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dUDSg7VeCzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "717a24ca-81aa-429d-c69d-c8a494a34840"
      },
      "source": [
        "layer_outs_for_single_instance(model, x_test[np.random.choice(len(y_test))])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "___________________________________________________________________________\n",
            "\u001b[1mLayer# : 1\n",
            "\u001b[1mName   : embedding_1\n",
            "\u001b[1mShape  : (1, 300, 100)\u001b[0m\n",
            "[[[-0.01472874  0.03862207 -0.00789142 ...  0.0353833  -0.02726978\n",
            "   -0.01185354]\n",
            "  [-0.01472874  0.03862207 -0.00789142 ...  0.0353833  -0.02726978\n",
            "   -0.01185354]\n",
            "  [-0.01472874  0.03862207 -0.00789142 ...  0.0353833  -0.02726978\n",
            "   -0.01185354]\n",
            "  ...\n",
            "  [ 0.02734203  0.0395744   0.00077729 ... -0.02001605  0.01918605\n",
            "    0.01954628]\n",
            "  [-0.03852933  0.02782103 -0.00494694 ...  0.02900696  0.04584566\n",
            "    0.0492037 ]\n",
            "  [ 0.02756107  0.00461642 -0.0453699  ... -0.0076103  -0.02313288\n",
            "   -0.00421534]]]\n",
            "___________________________________________________________________________\n",
            "\u001b[1mLayer# : 2\n",
            "\u001b[1mName   : lstm_1\n",
            "\u001b[1mShape  : (1, 64)\u001b[0m\n",
            "[[ 9.45082866e-04  3.36543960e-03  1.78135298e-02 -7.86926318e-03\n",
            "   1.98247680e-03  3.05092847e-03  9.42264870e-03 -1.24558862e-02\n",
            "  -5.21513913e-03  1.89300291e-02  7.33488286e-03  7.11964583e-03\n",
            "   8.43445479e-04 -8.40545818e-03  1.68919731e-02  1.72298793e-02\n",
            "  -6.04572333e-03 -1.50117436e-02  1.58114098e-02 -2.97207414e-04\n",
            "   3.01633903e-04  1.52029619e-02 -1.85263238e-03 -5.72952768e-03\n",
            "  -3.44699714e-03  1.46512818e-02 -1.17764238e-03  4.85222973e-03\n",
            "   6.44007232e-04  3.62510444e-04  5.89778088e-03 -2.07916298e-03\n",
            "  -1.39600942e-02 -1.00411510e-03 -5.26397629e-03  1.07000293e-02\n",
            "   9.30486806e-03 -4.77149663e-03 -3.57207656e-03 -1.03053236e-02\n",
            "  -1.75238978e-02 -1.75218924e-03  1.37255462e-02  4.74871881e-03\n",
            "  -6.51200302e-03 -3.38529097e-03 -1.10049695e-02  5.61200036e-03\n",
            "  -3.39799553e-05 -7.39507983e-03 -1.15060983e-02  5.37597435e-03\n",
            "  -5.02444617e-03  1.80633401e-03 -1.27596650e-02  2.13552325e-04\n",
            "   8.29503592e-03 -1.05528021e-02  5.51900477e-04 -6.61057932e-03\n",
            "   1.37532232e-02  2.45877588e-03  8.87858495e-03 -1.44654121e-02]]\n",
            "___________________________________________________________________________\n",
            "\u001b[1mLayer# : 3\n",
            "\u001b[1mName   : dense_1\n",
            "\u001b[1mShape  : (1, 64)\u001b[0m\n",
            "[[8.9872978e-05 1.5477960e-03 0.0000000e+00 1.4021548e-02 0.0000000e+00\n",
            "  0.0000000e+00 3.4300541e-04 1.0132790e-02 1.2591403e-02 0.0000000e+00\n",
            "  6.3492097e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 3.9210822e-03 0.0000000e+00 2.2311523e-03 0.0000000e+00\n",
            "  1.9005340e-02 1.5973752e-02 2.0752603e-02 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 3.8883255e-03 0.0000000e+00 0.0000000e+00 6.9625485e-03\n",
            "  0.0000000e+00 4.5670718e-03 0.0000000e+00 0.0000000e+00 1.1287245e-03\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  6.7499820e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  2.5882502e-03 3.5217353e-03 1.5466179e-02 0.0000000e+00 7.8768758e-03\n",
            "  0.0000000e+00 0.0000000e+00 7.2057080e-03 1.5723193e-04 3.6621983e-03\n",
            "  0.0000000e+00 1.7753971e-03 1.1343910e-02 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 3.1806063e-03 2.5454632e-03 0.0000000e+00]]\n",
            "___________________________________________________________________________\n",
            "\u001b[1mLayer# : 4\n",
            "\u001b[1mName   : dropout_1\n",
            "\u001b[1mShape  : (1, 64)\u001b[0m\n",
            "[[0.00017975 0.00309559 0.         0.0280431  0.         0.\n",
            "  0.00068601 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.0044623  0.         0.         0.0319475  0.04150521 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0051765  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.00031446\n",
            "  0.0073244  0.         0.         0.         0.         0.\n",
            "  0.         0.00636121 0.00509093 0.        ]]\n",
            "___________________________________________________________________________\n",
            "\u001b[1mLayer# : 5\n",
            "\u001b[1mName   : dense_2\n",
            "\u001b[1mShape  : (1, 1)\u001b[0m\n",
            "[[1.]]\n",
            "___________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tskt_1npeCzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}